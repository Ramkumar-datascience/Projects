{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e603eff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM, InputLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66415a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"\"\"Python is an interpreted, object-oriented, high-level programming language with dynamic semantics. Its high-level built in data structures, combined with dynamic typing and dynamic binding, make it very attractive for Rapid Application Development, as well as for use as a scripting or glue language to connect existing components together. Python's simple, easy to learn syntax emphasizes readability and therefore reduces the cost of program maintenance. Python supports modules and packages, which encourages program modularity and code reuse. The Python interpreter and the extensive standard library are available in source or binary form without charge for all major platforms, and can be freely distributed.\n",
    "\n",
    "Often, programmers fall in love with Python because of the increased productivity it provides. Since there is no compilation step, the edit-test-debug cycle is incredibly fast. Debugging Python programs is easy: a bug or bad input will never cause a segmentation fault. Instead, when the interpreter discovers an error, it raises an exception. When the program doesn't catch the exception, the interpreter prints a stack trace. A source level debugger allows inspection of local and global variables, evaluation of arbitrary expressions, setting breakpoints, stepping through the code a line at a time, and so on. The debugger is written in Python itself, testifying to Python's introspective power. On the other hand, often the quickest way to debug a program is to add a few print statements to the source: the fast edit-test-debug cycle makes this simple approach very effective.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce7460ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = Tokenizer()\n",
    "tokens.fit_on_texts([doc])\n",
    "total_words = len(tokens.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9648a954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e47966f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'a': 2,\n",
       " 'and': 3,\n",
       " 'python': 4,\n",
       " 'is': 5,\n",
       " 'to': 6,\n",
       " 'in': 7,\n",
       " 'of': 8,\n",
       " 'program': 9,\n",
       " 'an': 10,\n",
       " 'level': 11,\n",
       " 'with': 12,\n",
       " 'dynamic': 13,\n",
       " 'it': 14,\n",
       " 'for': 15,\n",
       " 'as': 16,\n",
       " 'or': 17,\n",
       " 'interpreter': 18,\n",
       " 'source': 19,\n",
       " 'debug': 20,\n",
       " 'high': 21,\n",
       " 'language': 22,\n",
       " 'very': 23,\n",
       " \"python's\": 24,\n",
       " 'simple': 25,\n",
       " 'easy': 26,\n",
       " 'code': 27,\n",
       " 'often': 28,\n",
       " 'edit': 29,\n",
       " 'test': 30,\n",
       " 'cycle': 31,\n",
       " 'fast': 32,\n",
       " 'when': 33,\n",
       " 'exception': 34,\n",
       " 'debugger': 35,\n",
       " 'on': 36,\n",
       " 'interpreted': 37,\n",
       " 'object': 38,\n",
       " 'oriented': 39,\n",
       " 'programming': 40,\n",
       " 'semantics': 41,\n",
       " 'its': 42,\n",
       " 'built': 43,\n",
       " 'data': 44,\n",
       " 'structures': 45,\n",
       " 'combined': 46,\n",
       " 'typing': 47,\n",
       " 'binding': 48,\n",
       " 'make': 49,\n",
       " 'attractive': 50,\n",
       " 'rapid': 51,\n",
       " 'application': 52,\n",
       " 'development': 53,\n",
       " 'well': 54,\n",
       " 'use': 55,\n",
       " 'scripting': 56,\n",
       " 'glue': 57,\n",
       " 'connect': 58,\n",
       " 'existing': 59,\n",
       " 'components': 60,\n",
       " 'together': 61,\n",
       " 'learn': 62,\n",
       " 'syntax': 63,\n",
       " 'emphasizes': 64,\n",
       " 'readability': 65,\n",
       " 'therefore': 66,\n",
       " 'reduces': 67,\n",
       " 'cost': 68,\n",
       " 'maintenance': 69,\n",
       " 'supports': 70,\n",
       " 'modules': 71,\n",
       " 'packages': 72,\n",
       " 'which': 73,\n",
       " 'encourages': 74,\n",
       " 'modularity': 75,\n",
       " 'reuse': 76,\n",
       " 'extensive': 77,\n",
       " 'standard': 78,\n",
       " 'library': 79,\n",
       " 'are': 80,\n",
       " 'available': 81,\n",
       " 'binary': 82,\n",
       " 'form': 83,\n",
       " 'without': 84,\n",
       " 'charge': 85,\n",
       " 'all': 86,\n",
       " 'major': 87,\n",
       " 'platforms': 88,\n",
       " 'can': 89,\n",
       " 'be': 90,\n",
       " 'freely': 91,\n",
       " 'distributed': 92,\n",
       " 'programmers': 93,\n",
       " 'fall': 94,\n",
       " 'love': 95,\n",
       " 'because': 96,\n",
       " 'increased': 97,\n",
       " 'productivity': 98,\n",
       " 'provides': 99,\n",
       " 'since': 100,\n",
       " 'there': 101,\n",
       " 'no': 102,\n",
       " 'compilation': 103,\n",
       " 'step': 104,\n",
       " 'incredibly': 105,\n",
       " 'debugging': 106,\n",
       " 'programs': 107,\n",
       " 'bug': 108,\n",
       " 'bad': 109,\n",
       " 'input': 110,\n",
       " 'will': 111,\n",
       " 'never': 112,\n",
       " 'cause': 113,\n",
       " 'segmentation': 114,\n",
       " 'fault': 115,\n",
       " 'instead': 116,\n",
       " 'discovers': 117,\n",
       " 'error': 118,\n",
       " 'raises': 119,\n",
       " \"doesn't\": 120,\n",
       " 'catch': 121,\n",
       " 'prints': 122,\n",
       " 'stack': 123,\n",
       " 'trace': 124,\n",
       " 'allows': 125,\n",
       " 'inspection': 126,\n",
       " 'local': 127,\n",
       " 'global': 128,\n",
       " 'variables': 129,\n",
       " 'evaluation': 130,\n",
       " 'arbitrary': 131,\n",
       " 'expressions': 132,\n",
       " 'setting': 133,\n",
       " 'breakpoints': 134,\n",
       " 'stepping': 135,\n",
       " 'through': 136,\n",
       " 'line': 137,\n",
       " 'at': 138,\n",
       " 'time': 139,\n",
       " 'so': 140,\n",
       " 'written': 141,\n",
       " 'itself': 142,\n",
       " 'testifying': 143,\n",
       " 'introspective': 144,\n",
       " 'power': 145,\n",
       " 'other': 146,\n",
       " 'hand': 147,\n",
       " 'quickest': 148,\n",
       " 'way': 149,\n",
       " 'add': 150,\n",
       " 'few': 151,\n",
       " 'print': 152,\n",
       " 'statements': 153,\n",
       " 'makes': 154,\n",
       " 'this': 155,\n",
       " 'approach': 156,\n",
       " 'effective': 157}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.word_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c44f2c27",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5]\n",
      "[4, 5, 10]\n",
      "[4, 5, 10, 37]\n",
      "[4, 5, 10, 37, 38]\n",
      "[4, 5, 10, 37, 38, 39]\n",
      "[4, 5, 10, 37, 38, 39, 21]\n",
      "[4, 5, 10, 37, 38, 39, 21, 11]\n",
      "[4, 5, 10, 37, 38, 39, 21, 11, 40]\n",
      "[4, 5, 10, 37, 38, 39, 21, 11, 40, 22]\n",
      "[4, 5, 10, 37, 38, 39, 21, 11, 40, 22, 12]\n",
      "[4, 5, 10, 37, 38, 39, 21, 11, 40, 22, 12, 13]\n",
      "[4, 5, 10, 37, 38, 39, 21, 11, 40, 22, 12, 13, 41]\n",
      "[4, 5, 10, 37, 38, 39, 21, 11, 40, 22, 12, 13, 41]\n",
      "[42, 21]\n",
      "[42, 21, 11]\n",
      "[42, 21, 11, 43]\n",
      "[42, 21, 11, 43, 7]\n",
      "[42, 21, 11, 43, 7, 44]\n",
      "[42, 21, 11, 43, 7, 44, 45]\n",
      "[42, 21, 11, 43, 7, 44, 45, 46]\n",
      "[42, 21, 11, 43, 7, 44, 45, 46, 12]\n",
      "[42, 21, 11, 43, 7, 44, 45, 46, 12, 13]\n",
      "[42, 21, 11, 43, 7, 44, 45, 46, 12, 13, 47]\n",
      "[42, 21, 11, 43, 7, 44, 45, 46, 12, 13, 47, 3]\n",
      "[42, 21, 11, 43, 7, 44, 45, 46, 12, 13, 47, 3, 13]\n",
      "[42, 21, 11, 43, 7, 44, 45, 46, 12, 13, 47, 3, 13, 48]\n",
      "[42, 21, 11, 43, 7, 44, 45, 46, 12, 13, 47, 3, 13, 48, 49]\n",
      "[42, 21, 11, 43, 7, 44, 45, 46, 12, 13, 47, 3, 13, 48, 49, 14]\n",
      "[42, 21, 11, 43, 7, 44, 45, 46, 12, 13, 47, 3, 13, 48, 49, 14, 23]\n",
      "[42, 21, 11, 43, 7, 44, 45, 46, 12, 13, 47, 3, 13, 48, 49, 14, 23, 50]\n",
      "[42, 21, 11, 43, 7, 44, 45, 46, 12, 13, 47, 3, 13, 48, 49, 14, 23, 50, 15]\n",
      "[42, 21, 11, 43, 7, 44, 45, 46, 12, 13, 47, 3, 13, 48, 49, 14, 23, 50, 15, 51]\n",
      "[42, 21, 11, 43, 7, 44, 45, 46, 12, 13, 47, 3, 13, 48, 49, 14, 23, 50, 15, 51, 52]\n",
      "[42, 21, 11, 43, 7, 44, 45, 46, 12, 13, 47, 3, 13, 48, 49, 14, 23, 50, 15, 51, 52, 53]\n",
      "[42, 21, 11, 43, 7, 44, 45, 46, 12, 13, 47, 3, 13, 48, 49, 14, 23, 50, 15, 51, 52, 53, 16]\n",
      "[42, 21, 11, 43, 7, 44, 45, 46, 12, 13, 47, 3, 13, 48, 49, 14, 23, 50, 15, 51, 52, 53, 16, 54]\n",
      "[42, 21, 11, 43, 7, 44, 45, 46, 12, 13, 47, 3, 13, 48, 49, 14, 23, 50, 15, 51, 52, 53, 16, 54, 16]\n",
      "[42, 21, 11, 43, 7, 44, 45, 46, 12, 13, 47, 3, 13, 48, 49, 14, 23, 50, 15, 51, 52, 53, 16, 54, 16, 15]\n",
      "[42, 21, 11, 43, 7, 44, 45, 46, 12, 13, 47, 3, 13, 48, 49, 14, 23, 50, 15, 51, 52, 53, 16, 54, 16, 15, 55]\n",
      "[42, 21, 11, 43, 7, 44, 45, 46, 12, 13, 47, 3, 13, 48, 49, 14, 23, 50, 15, 51, 52, 53, 16, 54, 16, 15, 55, 16]\n",
      "[42, 21, 11, 43, 7, 44, 45, 46, 12, 13, 47, 3, 13, 48, 49, 14, 23, 50, 15, 51, 52, 53, 16, 54, 16, 15, 55, 16, 2]\n",
      "[42, 21, 11, 43, 7, 44, 45, 46, 12, 13, 47, 3, 13, 48, 49, 14, 23, 50, 15, 51, 52, 53, 16, 54, 16, 15, 55, 16, 2, 56]\n",
      "[42, 21, 11, 43, 7, 44, 45, 46, 12, 13, 47, 3, 13, 48, 49, 14, 23, 50, 15, 51, 52, 53, 16, 54, 16, 15, 55, 16, 2, 56, 17]\n",
      "[42, 21, 11, 43, 7, 44, 45, 46, 12, 13, 47, 3, 13, 48, 49, 14, 23, 50, 15, 51, 52, 53, 16, 54, 16, 15, 55, 16, 2, 56, 17, 57]\n",
      "[42, 21, 11, 43, 7, 44, 45, 46, 12, 13, 47, 3, 13, 48, 49, 14, 23, 50, 15, 51, 52, 53, 16, 54, 16, 15, 55, 16, 2, 56, 17, 57, 22]\n",
      "[42, 21, 11, 43, 7, 44, 45, 46, 12, 13, 47, 3, 13, 48, 49, 14, 23, 50, 15, 51, 52, 53, 16, 54, 16, 15, 55, 16, 2, 56, 17, 57, 22, 6]\n",
      "[42, 21, 11, 43, 7, 44, 45, 46, 12, 13, 47, 3, 13, 48, 49, 14, 23, 50, 15, 51, 52, 53, 16, 54, 16, 15, 55, 16, 2, 56, 17, 57, 22, 6, 58]\n",
      "[42, 21, 11, 43, 7, 44, 45, 46, 12, 13, 47, 3, 13, 48, 49, 14, 23, 50, 15, 51, 52, 53, 16, 54, 16, 15, 55, 16, 2, 56, 17, 57, 22, 6, 58, 59]\n",
      "[42, 21, 11, 43, 7, 44, 45, 46, 12, 13, 47, 3, 13, 48, 49, 14, 23, 50, 15, 51, 52, 53, 16, 54, 16, 15, 55, 16, 2, 56, 17, 57, 22, 6, 58, 59, 60]\n",
      "[42, 21, 11, 43, 7, 44, 45, 46, 12, 13, 47, 3, 13, 48, 49, 14, 23, 50, 15, 51, 52, 53, 16, 54, 16, 15, 55, 16, 2, 56, 17, 57, 22, 6, 58, 59, 60, 61]\n",
      "[42, 21, 11, 43, 7, 44, 45, 46, 12, 13, 47, 3, 13, 48, 49, 14, 23, 50, 15, 51, 52, 53, 16, 54, 16, 15, 55, 16, 2, 56, 17, 57, 22, 6, 58, 59, 60, 61]\n",
      "[24, 25]\n",
      "[24, 25, 26]\n",
      "[24, 25, 26, 6]\n",
      "[24, 25, 26, 6, 62]\n",
      "[24, 25, 26, 6, 62, 63]\n",
      "[24, 25, 26, 6, 62, 63, 64]\n",
      "[24, 25, 26, 6, 62, 63, 64, 65]\n",
      "[24, 25, 26, 6, 62, 63, 64, 65, 3]\n",
      "[24, 25, 26, 6, 62, 63, 64, 65, 3, 66]\n",
      "[24, 25, 26, 6, 62, 63, 64, 65, 3, 66, 67]\n",
      "[24, 25, 26, 6, 62, 63, 64, 65, 3, 66, 67, 1]\n",
      "[24, 25, 26, 6, 62, 63, 64, 65, 3, 66, 67, 1, 68]\n",
      "[24, 25, 26, 6, 62, 63, 64, 65, 3, 66, 67, 1, 68, 8]\n",
      "[24, 25, 26, 6, 62, 63, 64, 65, 3, 66, 67, 1, 68, 8, 9]\n",
      "[24, 25, 26, 6, 62, 63, 64, 65, 3, 66, 67, 1, 68, 8, 9, 69]\n",
      "[24, 25, 26, 6, 62, 63, 64, 65, 3, 66, 67, 1, 68, 8, 9, 69]\n",
      "[4, 70]\n",
      "[4, 70, 71]\n",
      "[4, 70, 71, 3]\n",
      "[4, 70, 71, 3, 72]\n",
      "[4, 70, 71, 3, 72, 73]\n",
      "[4, 70, 71, 3, 72, 73, 74]\n",
      "[4, 70, 71, 3, 72, 73, 74, 9]\n",
      "[4, 70, 71, 3, 72, 73, 74, 9, 75]\n",
      "[4, 70, 71, 3, 72, 73, 74, 9, 75, 3]\n",
      "[4, 70, 71, 3, 72, 73, 74, 9, 75, 3, 27]\n",
      "[4, 70, 71, 3, 72, 73, 74, 9, 75, 3, 27, 76]\n",
      "[4, 70, 71, 3, 72, 73, 74, 9, 75, 3, 27, 76]\n",
      "[1, 4]\n",
      "[1, 4, 18]\n",
      "[1, 4, 18, 3]\n",
      "[1, 4, 18, 3, 1]\n",
      "[1, 4, 18, 3, 1, 77]\n",
      "[1, 4, 18, 3, 1, 77, 78]\n",
      "[1, 4, 18, 3, 1, 77, 78, 79]\n",
      "[1, 4, 18, 3, 1, 77, 78, 79, 80]\n",
      "[1, 4, 18, 3, 1, 77, 78, 79, 80, 81]\n",
      "[1, 4, 18, 3, 1, 77, 78, 79, 80, 81, 7]\n",
      "[1, 4, 18, 3, 1, 77, 78, 79, 80, 81, 7, 19]\n",
      "[1, 4, 18, 3, 1, 77, 78, 79, 80, 81, 7, 19, 17]\n",
      "[1, 4, 18, 3, 1, 77, 78, 79, 80, 81, 7, 19, 17, 82]\n",
      "[1, 4, 18, 3, 1, 77, 78, 79, 80, 81, 7, 19, 17, 82, 83]\n",
      "[1, 4, 18, 3, 1, 77, 78, 79, 80, 81, 7, 19, 17, 82, 83, 84]\n",
      "[1, 4, 18, 3, 1, 77, 78, 79, 80, 81, 7, 19, 17, 82, 83, 84, 85]\n",
      "[1, 4, 18, 3, 1, 77, 78, 79, 80, 81, 7, 19, 17, 82, 83, 84, 85, 15]\n",
      "[1, 4, 18, 3, 1, 77, 78, 79, 80, 81, 7, 19, 17, 82, 83, 84, 85, 15, 86]\n",
      "[1, 4, 18, 3, 1, 77, 78, 79, 80, 81, 7, 19, 17, 82, 83, 84, 85, 15, 86, 87]\n",
      "[1, 4, 18, 3, 1, 77, 78, 79, 80, 81, 7, 19, 17, 82, 83, 84, 85, 15, 86, 87, 88]\n",
      "[1, 4, 18, 3, 1, 77, 78, 79, 80, 81, 7, 19, 17, 82, 83, 84, 85, 15, 86, 87, 88, 3]\n",
      "[1, 4, 18, 3, 1, 77, 78, 79, 80, 81, 7, 19, 17, 82, 83, 84, 85, 15, 86, 87, 88, 3, 89]\n",
      "[1, 4, 18, 3, 1, 77, 78, 79, 80, 81, 7, 19, 17, 82, 83, 84, 85, 15, 86, 87, 88, 3, 89, 90]\n",
      "[1, 4, 18, 3, 1, 77, 78, 79, 80, 81, 7, 19, 17, 82, 83, 84, 85, 15, 86, 87, 88, 3, 89, 90, 91]\n",
      "[1, 4, 18, 3, 1, 77, 78, 79, 80, 81, 7, 19, 17, 82, 83, 84, 85, 15, 86, 87, 88, 3, 89, 90, 91, 92]\n",
      "[1, 4, 18, 3, 1, 77, 78, 79, 80, 81, 7, 19, 17, 82, 83, 84, 85, 15, 86, 87, 88, 3, 89, 90, 91, 92]\n",
      "[28, 93]\n",
      "[28, 93, 94]\n",
      "[28, 93, 94, 7]\n",
      "[28, 93, 94, 7, 95]\n",
      "[28, 93, 94, 7, 95, 12]\n",
      "[28, 93, 94, 7, 95, 12, 4]\n",
      "[28, 93, 94, 7, 95, 12, 4, 96]\n",
      "[28, 93, 94, 7, 95, 12, 4, 96, 8]\n",
      "[28, 93, 94, 7, 95, 12, 4, 96, 8, 1]\n",
      "[28, 93, 94, 7, 95, 12, 4, 96, 8, 1, 97]\n",
      "[28, 93, 94, 7, 95, 12, 4, 96, 8, 1, 97, 98]\n",
      "[28, 93, 94, 7, 95, 12, 4, 96, 8, 1, 97, 98, 14]\n",
      "[28, 93, 94, 7, 95, 12, 4, 96, 8, 1, 97, 98, 14, 99]\n",
      "[28, 93, 94, 7, 95, 12, 4, 96, 8, 1, 97, 98, 14, 99]\n",
      "[100, 101]\n",
      "[100, 101, 5]\n",
      "[100, 101, 5, 102]\n",
      "[100, 101, 5, 102, 103]\n",
      "[100, 101, 5, 102, 103, 104]\n",
      "[100, 101, 5, 102, 103, 104, 1]\n",
      "[100, 101, 5, 102, 103, 104, 1, 29]\n",
      "[100, 101, 5, 102, 103, 104, 1, 29, 30]\n",
      "[100, 101, 5, 102, 103, 104, 1, 29, 30, 20]\n",
      "[100, 101, 5, 102, 103, 104, 1, 29, 30, 20, 31]\n",
      "[100, 101, 5, 102, 103, 104, 1, 29, 30, 20, 31, 5]\n",
      "[100, 101, 5, 102, 103, 104, 1, 29, 30, 20, 31, 5, 105]\n",
      "[100, 101, 5, 102, 103, 104, 1, 29, 30, 20, 31, 5, 105, 32]\n",
      "[100, 101, 5, 102, 103, 104, 1, 29, 30, 20, 31, 5, 105, 32]\n",
      "[106, 4]\n",
      "[106, 4, 107]\n",
      "[106, 4, 107, 5]\n",
      "[106, 4, 107, 5, 26]\n",
      "[106, 4, 107, 5, 26, 2]\n",
      "[106, 4, 107, 5, 26, 2, 108]\n",
      "[106, 4, 107, 5, 26, 2, 108, 17]\n",
      "[106, 4, 107, 5, 26, 2, 108, 17, 109]\n",
      "[106, 4, 107, 5, 26, 2, 108, 17, 109, 110]\n",
      "[106, 4, 107, 5, 26, 2, 108, 17, 109, 110, 111]\n",
      "[106, 4, 107, 5, 26, 2, 108, 17, 109, 110, 111, 112]\n",
      "[106, 4, 107, 5, 26, 2, 108, 17, 109, 110, 111, 112, 113]\n",
      "[106, 4, 107, 5, 26, 2, 108, 17, 109, 110, 111, 112, 113, 2]\n",
      "[106, 4, 107, 5, 26, 2, 108, 17, 109, 110, 111, 112, 113, 2, 114]\n",
      "[106, 4, 107, 5, 26, 2, 108, 17, 109, 110, 111, 112, 113, 2, 114, 115]\n",
      "[106, 4, 107, 5, 26, 2, 108, 17, 109, 110, 111, 112, 113, 2, 114, 115]\n",
      "[116, 33]\n",
      "[116, 33, 1]\n",
      "[116, 33, 1, 18]\n",
      "[116, 33, 1, 18, 117]\n",
      "[116, 33, 1, 18, 117, 10]\n",
      "[116, 33, 1, 18, 117, 10, 118]\n",
      "[116, 33, 1, 18, 117, 10, 118, 14]\n",
      "[116, 33, 1, 18, 117, 10, 118, 14, 119]\n",
      "[116, 33, 1, 18, 117, 10, 118, 14, 119, 10]\n",
      "[116, 33, 1, 18, 117, 10, 118, 14, 119, 10, 34]\n",
      "[116, 33, 1, 18, 117, 10, 118, 14, 119, 10, 34]\n",
      "[33, 1]\n",
      "[33, 1, 9]\n",
      "[33, 1, 9, 120]\n",
      "[33, 1, 9, 120, 121]\n",
      "[33, 1, 9, 120, 121, 1]\n",
      "[33, 1, 9, 120, 121, 1, 34]\n",
      "[33, 1, 9, 120, 121, 1, 34, 1]\n",
      "[33, 1, 9, 120, 121, 1, 34, 1, 18]\n",
      "[33, 1, 9, 120, 121, 1, 34, 1, 18, 122]\n",
      "[33, 1, 9, 120, 121, 1, 34, 1, 18, 122, 2]\n",
      "[33, 1, 9, 120, 121, 1, 34, 1, 18, 122, 2, 123]\n",
      "[33, 1, 9, 120, 121, 1, 34, 1, 18, 122, 2, 123, 124]\n",
      "[33, 1, 9, 120, 121, 1, 34, 1, 18, 122, 2, 123, 124]\n",
      "[2, 19]\n",
      "[2, 19, 11]\n",
      "[2, 19, 11, 35]\n",
      "[2, 19, 11, 35, 125]\n",
      "[2, 19, 11, 35, 125, 126]\n",
      "[2, 19, 11, 35, 125, 126, 8]\n",
      "[2, 19, 11, 35, 125, 126, 8, 127]\n",
      "[2, 19, 11, 35, 125, 126, 8, 127, 3]\n",
      "[2, 19, 11, 35, 125, 126, 8, 127, 3, 128]\n",
      "[2, 19, 11, 35, 125, 126, 8, 127, 3, 128, 129]\n",
      "[2, 19, 11, 35, 125, 126, 8, 127, 3, 128, 129, 130]\n",
      "[2, 19, 11, 35, 125, 126, 8, 127, 3, 128, 129, 130, 8]\n",
      "[2, 19, 11, 35, 125, 126, 8, 127, 3, 128, 129, 130, 8, 131]\n",
      "[2, 19, 11, 35, 125, 126, 8, 127, 3, 128, 129, 130, 8, 131, 132]\n",
      "[2, 19, 11, 35, 125, 126, 8, 127, 3, 128, 129, 130, 8, 131, 132, 133]\n",
      "[2, 19, 11, 35, 125, 126, 8, 127, 3, 128, 129, 130, 8, 131, 132, 133, 134]\n",
      "[2, 19, 11, 35, 125, 126, 8, 127, 3, 128, 129, 130, 8, 131, 132, 133, 134, 135]\n",
      "[2, 19, 11, 35, 125, 126, 8, 127, 3, 128, 129, 130, 8, 131, 132, 133, 134, 135, 136]\n",
      "[2, 19, 11, 35, 125, 126, 8, 127, 3, 128, 129, 130, 8, 131, 132, 133, 134, 135, 136, 1]\n",
      "[2, 19, 11, 35, 125, 126, 8, 127, 3, 128, 129, 130, 8, 131, 132, 133, 134, 135, 136, 1, 27]\n",
      "[2, 19, 11, 35, 125, 126, 8, 127, 3, 128, 129, 130, 8, 131, 132, 133, 134, 135, 136, 1, 27, 2]\n",
      "[2, 19, 11, 35, 125, 126, 8, 127, 3, 128, 129, 130, 8, 131, 132, 133, 134, 135, 136, 1, 27, 2, 137]\n",
      "[2, 19, 11, 35, 125, 126, 8, 127, 3, 128, 129, 130, 8, 131, 132, 133, 134, 135, 136, 1, 27, 2, 137, 138]\n",
      "[2, 19, 11, 35, 125, 126, 8, 127, 3, 128, 129, 130, 8, 131, 132, 133, 134, 135, 136, 1, 27, 2, 137, 138, 2]\n",
      "[2, 19, 11, 35, 125, 126, 8, 127, 3, 128, 129, 130, 8, 131, 132, 133, 134, 135, 136, 1, 27, 2, 137, 138, 2, 139]\n",
      "[2, 19, 11, 35, 125, 126, 8, 127, 3, 128, 129, 130, 8, 131, 132, 133, 134, 135, 136, 1, 27, 2, 137, 138, 2, 139, 3]\n",
      "[2, 19, 11, 35, 125, 126, 8, 127, 3, 128, 129, 130, 8, 131, 132, 133, 134, 135, 136, 1, 27, 2, 137, 138, 2, 139, 3, 140]\n",
      "[2, 19, 11, 35, 125, 126, 8, 127, 3, 128, 129, 130, 8, 131, 132, 133, 134, 135, 136, 1, 27, 2, 137, 138, 2, 139, 3, 140, 36]\n",
      "[2, 19, 11, 35, 125, 126, 8, 127, 3, 128, 129, 130, 8, 131, 132, 133, 134, 135, 136, 1, 27, 2, 137, 138, 2, 139, 3, 140, 36]\n",
      "[1, 35]\n",
      "[1, 35, 5]\n",
      "[1, 35, 5, 141]\n",
      "[1, 35, 5, 141, 7]\n",
      "[1, 35, 5, 141, 7, 4]\n",
      "[1, 35, 5, 141, 7, 4, 142]\n",
      "[1, 35, 5, 141, 7, 4, 142, 143]\n",
      "[1, 35, 5, 141, 7, 4, 142, 143, 6]\n",
      "[1, 35, 5, 141, 7, 4, 142, 143, 6, 24]\n",
      "[1, 35, 5, 141, 7, 4, 142, 143, 6, 24, 144]\n",
      "[1, 35, 5, 141, 7, 4, 142, 143, 6, 24, 144, 145]\n",
      "[1, 35, 5, 141, 7, 4, 142, 143, 6, 24, 144, 145]\n",
      "[36, 1]\n",
      "[36, 1, 146]\n",
      "[36, 1, 146, 147]\n",
      "[36, 1, 146, 147, 28]\n",
      "[36, 1, 146, 147, 28, 1]\n",
      "[36, 1, 146, 147, 28, 1, 148]\n",
      "[36, 1, 146, 147, 28, 1, 148, 149]\n",
      "[36, 1, 146, 147, 28, 1, 148, 149, 6]\n",
      "[36, 1, 146, 147, 28, 1, 148, 149, 6, 20]\n",
      "[36, 1, 146, 147, 28, 1, 148, 149, 6, 20, 2]\n",
      "[36, 1, 146, 147, 28, 1, 148, 149, 6, 20, 2, 9]\n",
      "[36, 1, 146, 147, 28, 1, 148, 149, 6, 20, 2, 9, 5]\n",
      "[36, 1, 146, 147, 28, 1, 148, 149, 6, 20, 2, 9, 5, 6]\n",
      "[36, 1, 146, 147, 28, 1, 148, 149, 6, 20, 2, 9, 5, 6, 150]\n",
      "[36, 1, 146, 147, 28, 1, 148, 149, 6, 20, 2, 9, 5, 6, 150, 2]\n",
      "[36, 1, 146, 147, 28, 1, 148, 149, 6, 20, 2, 9, 5, 6, 150, 2, 151]\n",
      "[36, 1, 146, 147, 28, 1, 148, 149, 6, 20, 2, 9, 5, 6, 150, 2, 151, 152]\n",
      "[36, 1, 146, 147, 28, 1, 148, 149, 6, 20, 2, 9, 5, 6, 150, 2, 151, 152, 153]\n",
      "[36, 1, 146, 147, 28, 1, 148, 149, 6, 20, 2, 9, 5, 6, 150, 2, 151, 152, 153, 6]\n",
      "[36, 1, 146, 147, 28, 1, 148, 149, 6, 20, 2, 9, 5, 6, 150, 2, 151, 152, 153, 6, 1]\n",
      "[36, 1, 146, 147, 28, 1, 148, 149, 6, 20, 2, 9, 5, 6, 150, 2, 151, 152, 153, 6, 1, 19]\n",
      "[36, 1, 146, 147, 28, 1, 148, 149, 6, 20, 2, 9, 5, 6, 150, 2, 151, 152, 153, 6, 1, 19, 1]\n",
      "[36, 1, 146, 147, 28, 1, 148, 149, 6, 20, 2, 9, 5, 6, 150, 2, 151, 152, 153, 6, 1, 19, 1, 32]\n",
      "[36, 1, 146, 147, 28, 1, 148, 149, 6, 20, 2, 9, 5, 6, 150, 2, 151, 152, 153, 6, 1, 19, 1, 32, 29]\n",
      "[36, 1, 146, 147, 28, 1, 148, 149, 6, 20, 2, 9, 5, 6, 150, 2, 151, 152, 153, 6, 1, 19, 1, 32, 29, 30]\n",
      "[36, 1, 146, 147, 28, 1, 148, 149, 6, 20, 2, 9, 5, 6, 150, 2, 151, 152, 153, 6, 1, 19, 1, 32, 29, 30, 20]\n",
      "[36, 1, 146, 147, 28, 1, 148, 149, 6, 20, 2, 9, 5, 6, 150, 2, 151, 152, 153, 6, 1, 19, 1, 32, 29, 30, 20, 31]\n",
      "[36, 1, 146, 147, 28, 1, 148, 149, 6, 20, 2, 9, 5, 6, 150, 2, 151, 152, 153, 6, 1, 19, 1, 32, 29, 30, 20, 31, 154]\n",
      "[36, 1, 146, 147, 28, 1, 148, 149, 6, 20, 2, 9, 5, 6, 150, 2, 151, 152, 153, 6, 1, 19, 1, 32, 29, 30, 20, 31, 154, 155]\n",
      "[36, 1, 146, 147, 28, 1, 148, 149, 6, 20, 2, 9, 5, 6, 150, 2, 151, 152, 153, 6, 1, 19, 1, 32, 29, 30, 20, 31, 154, 155, 25]\n",
      "[36, 1, 146, 147, 28, 1, 148, 149, 6, 20, 2, 9, 5, 6, 150, 2, 151, 152, 153, 6, 1, 19, 1, 32, 29, 30, 20, 31, 154, 155, 25, 156]\n",
      "[36, 1, 146, 147, 28, 1, 148, 149, 6, 20, 2, 9, 5, 6, 150, 2, 151, 152, 153, 6, 1, 19, 1, 32, 29, 30, 20, 31, 154, 155, 25, 156, 23]\n",
      "[36, 1, 146, 147, 28, 1, 148, 149, 6, 20, 2, 9, 5, 6, 150, 2, 151, 152, 153, 6, 1, 19, 1, 32, 29, 30, 20, 31, 154, 155, 25, 156, 23, 157]\n",
      "[36, 1, 146, 147, 28, 1, 148, 149, 6, 20, 2, 9, 5, 6, 150, 2, 151, 152, 153, 6, 1, 19, 1, 32, 29, 30, 20, 31, 154, 155, 25, 156, 23, 157]\n"
     ]
    }
   ],
   "source": [
    "input_seq = []\n",
    "for sentance in doc.split(\".\"):\n",
    "    #print(sentance)\n",
    "    #print(tokens.texts_to_sequences([sentance])[0])\n",
    "    sentance_token = tokens.texts_to_sequences([sentance])[0]\n",
    "    for i in range(1, len(sentance_token)+1):\n",
    "        n_gram_seq = sentance_token[:i+1]\n",
    "        print(n_gram_seq)\n",
    "        input_seq.append(n_gram_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1b62534a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seqquence_len = max([len(i) for i in input_seq])\n",
    "max_seqquence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "59aab059",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pad_sequence = pad_sequences(input_seq,maxlen=max_seqquence_len, padding=\"pre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58698684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 5])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_pad_sequence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a9745b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = my_pad_sequence[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7bba0bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = my_pad_sequence[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d7856d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248, 37)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "46d722f5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5,  10,  37,  38,  39,  21,  11,  40,  22,  12,  13,  41,  41,\n",
       "        21,  11,  43,   7,  44,  45,  46,  12,  13,  47,   3,  13,  48,\n",
       "        49,  14,  23,  50,  15,  51,  52,  53,  16,  54,  16,  15,  55,\n",
       "        16,   2,  56,  17,  57,  22,   6,  58,  59,  60,  61,  61,  25,\n",
       "        26,   6,  62,  63,  64,  65,   3,  66,  67,   1,  68,   8,   9,\n",
       "        69,  69,  70,  71,   3,  72,  73,  74,   9,  75,   3,  27,  76,\n",
       "        76,   4,  18,   3,   1,  77,  78,  79,  80,  81,   7,  19,  17,\n",
       "        82,  83,  84,  85,  15,  86,  87,  88,   3,  89,  90,  91,  92,\n",
       "        92,  93,  94,   7,  95,  12,   4,  96,   8,   1,  97,  98,  14,\n",
       "        99,  99, 101,   5, 102, 103, 104,   1,  29,  30,  20,  31,   5,\n",
       "       105,  32,  32,   4, 107,   5,  26,   2, 108,  17, 109, 110, 111,\n",
       "       112, 113,   2, 114, 115, 115,  33,   1,  18, 117,  10, 118,  14,\n",
       "       119,  10,  34,  34,   1,   9, 120, 121,   1,  34,   1,  18, 122,\n",
       "         2, 123, 124, 124,  19,  11,  35, 125, 126,   8, 127,   3, 128,\n",
       "       129, 130,   8, 131, 132, 133, 134, 135, 136,   1,  27,   2, 137,\n",
       "       138,   2, 139,   3, 140,  36,  36,  35,   5, 141,   7,   4, 142,\n",
       "       143,   6,  24, 144, 145, 145,   1, 146, 147,  28,   1, 148, 149,\n",
       "         6,  20,   2,   9,   5,   6, 150,   2, 151, 152, 153,   6,   1,\n",
       "        19,   1,  32,  29,  30,  20,  31, 154, 155,  25, 156,  23, 157,\n",
       "       157])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "82909e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tensorflow.keras.utils.to_categorical(y,num_classes=total_words+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b703dad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "baa5c47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9ea30e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seqquence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "23683ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_18\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_18\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">15,800</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">158</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">23,858</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_15 (\u001b[38;5;33mEmbedding\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m100\u001b[0m)             │          \u001b[38;5;34m15,800\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_11 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)                 │         \u001b[38;5;34m150,600\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m158\u001b[0m)                 │          \u001b[38;5;34m23,858\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">190,258</span> (743.20 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m190,258\u001b[0m (743.20 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">190,258</span> (743.20 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m190,258\u001b[0m (743.20 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer(shape=(37,)))\n",
    "model.add(Embedding(total_words+1, 100))\n",
    "\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(total_words+1, activation=\"softmax\"))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "78bea67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.0114 - loss: 5.0607 \n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0352 - loss: 4.9896  \n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0415 - loss: 4.8593\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0656 - loss: 4.8010\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0724 - loss: 4.6949\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0634 - loss: 4.6888\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0690 - loss: 4.5934\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0916 - loss: 4.4680\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0662 - loss: 4.4082\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1217 - loss: 4.2287\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0714 - loss: 4.1385\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1062 - loss: 4.0973\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.1424 - loss: 3.9290\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.1360 - loss: 3.8007\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1597 - loss: 3.7489\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1652 - loss: 3.5945\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1813 - loss: 3.4531\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2410 - loss: 3.3187\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2552 - loss: 3.1290\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2122 - loss: 3.1572\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2709 - loss: 2.9880\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2638 - loss: 2.8696\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2976 - loss: 2.7695\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2950 - loss: 2.6539\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3102 - loss: 2.6218\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3319 - loss: 2.4540\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3650 - loss: 2.3626\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3988 - loss: 2.3008\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3673 - loss: 2.3132\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4523 - loss: 2.0941\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4486 - loss: 2.0612\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5301 - loss: 1.9681\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4988 - loss: 1.9332\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5519 - loss: 1.8391\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5745 - loss: 1.7779\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5957 - loss: 1.7440\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6604 - loss: 1.6482\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6589 - loss: 1.6519\n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6930 - loss: 1.5492\n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6993 - loss: 1.5069\n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7472 - loss: 1.4615\n",
      "Epoch 42/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7221 - loss: 1.3936\n",
      "Epoch 43/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7854 - loss: 1.3661\n",
      "Epoch 44/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7675 - loss: 1.3901\n",
      "Epoch 45/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7914 - loss: 1.2807\n",
      "Epoch 46/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7960 - loss: 1.2601\n",
      "Epoch 47/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8332 - loss: 1.2157\n",
      "Epoch 48/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8257 - loss: 1.2071\n",
      "Epoch 49/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8675 - loss: 1.1268\n",
      "Epoch 50/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8811 - loss: 1.1395\n",
      "Epoch 51/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8611 - loss: 1.1098\n",
      "Epoch 52/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8707 - loss: 1.1119\n",
      "Epoch 53/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9129 - loss: 1.0355\n",
      "Epoch 54/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8894 - loss: 1.0390\n",
      "Epoch 55/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9242 - loss: 0.9533\n",
      "Epoch 56/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9203 - loss: 0.9340\n",
      "Epoch 57/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9317 - loss: 0.9151\n",
      "Epoch 58/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9440 - loss: 0.8641\n",
      "Epoch 59/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9656 - loss: 0.8113\n",
      "Epoch 60/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9505 - loss: 0.8191\n",
      "Epoch 61/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9522 - loss: 0.7815\n",
      "Epoch 62/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9557 - loss: 0.7700\n",
      "Epoch 63/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9708 - loss: 0.7351\n",
      "Epoch 64/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9856 - loss: 0.6730\n",
      "Epoch 65/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9529 - loss: 0.6928\n",
      "Epoch 66/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9697 - loss: 0.6779\n",
      "Epoch 67/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9498 - loss: 0.6813\n",
      "Epoch 68/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9783 - loss: 0.6157\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9670 - loss: 0.6206\n",
      "Epoch 70/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9652 - loss: 0.5893\n",
      "Epoch 71/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9793 - loss: 0.5562\n",
      "Epoch 72/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9707 - loss: 0.5609\n",
      "Epoch 73/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9757 - loss: 0.5406\n",
      "Epoch 74/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9706 - loss: 0.5002\n",
      "Epoch 75/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9789 - loss: 0.4860\n",
      "Epoch 76/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9805 - loss: 0.4668\n",
      "Epoch 77/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9855 - loss: 0.4678\n",
      "Epoch 78/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9745 - loss: 0.4396\n",
      "Epoch 79/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9783 - loss: 0.4465\n",
      "Epoch 80/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9756 - loss: 0.4217\n",
      "Epoch 81/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9726 - loss: 0.4066\n",
      "Epoch 82/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9855 - loss: 0.4120\n",
      "Epoch 83/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9810 - loss: 0.3826\n",
      "Epoch 84/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9856 - loss: 0.3634\n",
      "Epoch 85/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9968 - loss: 0.3484\n",
      "Epoch 86/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9934 - loss: 0.3396\n",
      "Epoch 87/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9862 - loss: 0.3400\n",
      "Epoch 88/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9914 - loss: 0.3272\n",
      "Epoch 89/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9892 - loss: 0.3167\n",
      "Epoch 90/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9900 - loss: 0.3204\n",
      "Epoch 91/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9883 - loss: 0.2981\n",
      "Epoch 92/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9854 - loss: 0.3151\n",
      "Epoch 93/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9922 - loss: 0.2884\n",
      "Epoch 94/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9892 - loss: 0.2699\n",
      "Epoch 95/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9810 - loss: 0.2699\n",
      "Epoch 96/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9977 - loss: 0.2558\n",
      "Epoch 97/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9933 - loss: 0.2486\n",
      "Epoch 98/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9977 - loss: 0.2423\n",
      "Epoch 99/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9966 - loss: 0.2228\n",
      "Epoch 100/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9918 - loss: 0.2364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1a5f10b3ad0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x, y, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e34ce7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "[1]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "[1, 4]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "[1, 4, 18]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "[1, 4, 18, 3]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "[1, 4, 18, 3, 1]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "[1, 4, 18, 3, 1, 77]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "[1, 4, 18, 3, 1, 77, 78]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "[1, 4, 18, 3, 1, 77, 78, 79]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "[1, 4, 18, 3, 1, 77, 78, 79, 80]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "ram kumar the python interpreter and the extensive standard library are available\n"
     ]
    }
   ],
   "source": [
    "input_text = \"ram kumar\"\n",
    "predict_next_words= 10\n",
    "\n",
    "for _ in range(predict_next_words):\n",
    "    token_list = tokens.texts_to_sequences([input_text])[0]\n",
    "    print(token_list)\n",
    "    token_list = pad_sequences([token_list], maxlen=max_seqquence_len-1, padding='pre')\n",
    "    predicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "    output_word = \"\"\n",
    "    for word, index in tokens.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    input_text += \" \" + output_word\n",
    "\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742e6d73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
